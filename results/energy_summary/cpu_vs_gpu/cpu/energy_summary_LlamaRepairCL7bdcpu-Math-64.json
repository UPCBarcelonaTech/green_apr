{
    "TOOL_BUG_ID": "LlamaRepairCL7bdcpu-Math-64",
    "Time": {
        "mean": 343.6217360496521,
        "median": 343.6217360496521,
        "std": 0.0,
        "max": 343.6217360496521,
        "min": 343.6217360496521,
        "count": 3
    },
    "Joules": {
        "mean": 354073.98075816635,
        "median": 354073.98075816635,
        "std": 0.0,
        "max": 354073.98075816635,
        "min": 354073.98075816635,
        "count": 3
    },
    "JoulesNormalized": {
        "mean": 97880.21983518603,
        "median": 97880.21983518603,
        "std": 0.0,
        "max": 97880.21983518603,
        "min": 97880.21983518603,
        "count": 3
    },
    "NrExecutions": 3,
    "ExecutionsIds": [
        "s1",
        "s2",
        "s3"
    ],
    "ExecutionsInferenceIds": [
        "s1_cpu",
        "s4_cpu",
        "s5_cpu"
    ],
    "NrExecutionsInference": 3,
    "NrPatches": {
        "median": 0,
        "std": 0.0,
        "max": 0,
        "min": 0
    },
    "Correctness_Per_Patch": [
        "W",
        "W",
        "W",
        "W",
        "W",
        "W",
        "W",
        "W",
        "W",
        "W"
    ],
    "Correctness_Per_Patch_original": [
        "uncompilable",
        "uncompilable",
        "uncompilable",
        "uncompilable",
        "uncompilable",
        "uncompilable",
        "uncompilable",
        "uncompilable",
        "uncompilable",
        "uncompilable"
    ],
    "patches": [
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n",
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n",
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n",
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n",
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n",
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n",
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n",
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n",
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n",
        "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex b41456e..5091493 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -255,8 +255,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         double[] diag    = new double[cols];\n         double[] oldX    = new double[cols];\n         double[] oldRes  = new double[rows];\n-        double[] oldObj  = new double[rows];\n-        double[] qtf     = new double[rows];\n         double[] work1   = new double[cols];\n         double[] work2   = new double[cols];\n         double[] work3   = new double[cols];\n@@ -269,9 +267,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n         boolean firstIteration = true;\n         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n         while (true) {\n-            for (int i=0;i<rows;i++) {\n-                qtf[i]=residuals[i];\n-            }\n             incrementIterationsCounter();\n \n             // compute the Q.R. decomposition of the jacobian matrix\n@@ -280,7 +275,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             qrDecomposition();\n \n             // compute Qt.res\n-            qTy(qtf);\n+            qTy(residuals);\n             // now we don't need Q anymore,\n             // so let jacobian contain the R matrix with its diagonal elements\n             for (int k = 0; k < solvedCols; ++k) {\n@@ -318,7 +313,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     if (s != 0) {\n                         double sum = 0;\n                         for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * qtf[i];\n+                            sum += jacobian[i][pj] * residuals[i];\n                         }\n                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                     }\n@@ -326,8 +321,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n             }\n             if (maxCosine <= orthoTolerance) {\n                 // convergence has been reached\n-            \tupdateResidualsAndCost();\n-            \tcurrent = new VectorialPointValuePair(point, objective);\n                 return current;\n             }\n \n@@ -348,12 +341,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                 double[] tmpVec = residuals;\n                 residuals = oldRes;\n                 oldRes    = tmpVec;\n-                tmpVec    = objective;\n-                objective = oldObj;\n-                oldObj    = tmpVec;\n \n                 // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(qtf, delta, diag, work1, work2, work3);\n+                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n \n                 // compute the new point and the norm of the evolution direction\n                 double lmNorm = 0;\n@@ -372,6 +362,7 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n                 // evaluate the function at x + p and calculate its norm\n                 updateResidualsAndCost();\n+                current = new VectorialPointValuePair(point, objective);\n \n                 // compute the scaled actual reduction\n                 double actRed = -1.0;\n@@ -427,15 +418,9 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                         xNorm    += xK * xK;\n                     }\n                     xNorm = Math.sqrt(xNorm);\n-                    current = new VectorialPointValuePair(point, objective);\n \n                     // tests for convergence.\n-                    if (checker != null) {\n                     // we use the vectorial convergence checker\n-                    \tif (checker.converged(getIterations(), previous, current)) {\n-                    \t\treturn current;\n-                    \t}\n-                    }\n                 } else {\n                     // failed iteration, reset the previous values\n                     cost = previousCost;\n@@ -446,9 +431,6 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                     tmpVec    = residuals;\n                     residuals = oldRes;\n                     oldRes    = tmpVec;\n-                    tmpVec    = objective;\n-                    objective = oldObj;\n-                    oldObj    = tmpVec;\n                 }\n                 if (checker==null) {\n                 \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n@@ -457,6 +439,10 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n+                } else {\n+                    if (checker.converged(getIterations(), previous, current)) {\n+                        return current;\n+                    }\n                 }\n                 // tests for termination and stringent tolerances\n                 // (2.2204e-16 is the machine epsilon for IEEE754)\n"
    ]
}