{
  "hostname": "gemini-2.lyon.grid5000.fr",
  "GPR[SSLB]": "1728437431729",
  "GPR[ESLB]": "1728437451749",
  "id": "132",
  "project": "Closure",
  "file": null,
  "input": null,
  "nvidea": null,
  "OAR_JOB_ID": "1711701",
  "GPR[SSLI]": "1728436251771",
  "GPR[ESLI]": "1728436281802",
  "GPR[SPS]": "1728437451786",
  "error": "CUDA out of memory. Tried to allocate 2.05 GiB (GPU 0; 31.74 GiB total capacity; 28.38 GiB already allocated; 285.38 MiB free; 31.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
  "GPR[EPS]": "1728437453685",
  "time": 1899,
  "output": null
}